{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Job scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the mean delay with the bimodal distribution, we would need to divide all results by five because the calculations are made with a mean job size of five."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages and define the plot function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this line if you prefer dynamic matplotlib plots\n",
    "# %matplotlib notebook\n",
    "\n",
    "# change the default figure size\n",
    "pylab.rcParams['figure.figsize'] = (7, 5)\n",
    "pylab.rcParams['legend.fontsize'] = 12\n",
    "\n",
    "markers = ['x', '+', '*']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manipulate dataframes\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder where the output of compute.sh is stored\n",
    "folder = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "rho = concatenate((linspace(0., .98, 1000, endpoint=False), linspace(.98, 1., 100, endpoint=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def toy_example(scenario, metric, bf, job_size_distribution, mean_job_size):\n",
    "    fig, axes = subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "    \n",
    "    for i in range(2):\n",
    "        maximum = 0.\n",
    "        \n",
    "        # theoretical results\n",
    "        if metric == 'service-rate':\n",
    "            axes[i].plot(rho, 1. / bf(rho, i),\n",
    "                         label='Balanced fairness', color='C0')\n",
    "        elif metric == 'delay':\n",
    "            axes[i].plot(rho, mean_job_size * bf(rho, i),\n",
    "                         label='Balanced fairness', color='C0')\n",
    "        \n",
    "        for j, timer in enumerate([5, 1, 0]):\n",
    "            # read the simulation results\n",
    "            result = pd.read_csv('%s%s-%s-%d-%s.csv'\n",
    "                                 % (folder, scenario, job_size_distribution, timer, metric))\n",
    "            \n",
    "            # plot the simulation results\n",
    "            axes[i].plot(result['rho'], result['performance%d' % i],\n",
    "                         label='m = %d' % timer, marker=markers[j],\n",
    "                         color='C%d' % (j+1), linestyle='None')\n",
    "            axes[i].fill_between(result['rho'],\n",
    "                                 (result['performance%d' % i] - result['interval%d' % i]),\n",
    "                                 (result['performance%d' % i] + result['interval%d' % i]),\n",
    "                                 color='C%d' % (j+1), alpha=.3)\n",
    "            \n",
    "            # remember the maximum ordinate\n",
    "            maximum = max(maximum, np.max(result['performance%d' % i] + result['interval%d' % i]))\n",
    "\n",
    "        axes[i].set_title('Pool %d (%s - %s - %s)' % (i+1, scenario, job_size_distribution, metric))\n",
    "        axes[i].set_xlim(0, 1); axes[i].set_ylim(0, maximum)\n",
    "        axes[i].legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Three servers (the M model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following formula computes performance under balanced fairness. It is recalled in Section 7.3.1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_model(rho, i):\n",
    "    return 1. / (3. * (1.-rho)) + 1. / (2. * (3. - 3. * rho + (9./16.) * rho * rho))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bimodal number of exponentially-distributed phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='m', metric='delay', bf=m_model,\n",
    "            job_size_distribution='bimodal', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='m', metric='service-rate', bf=m_model,\n",
    "            job_size_distribution='bimodal', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperexponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='m', metric='delay', bf=m_model,\n",
    "            job_size_distribution='hyperexp', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='m', metric='service-rate', bf=m_model,\n",
    "            job_size_distribution='hyperexp', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zipf number of exponentially-distributed phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='m', metric='delay', bf=m_model,\n",
    "            job_size_distribution='zipf', mean_job_size=3.584282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='m', metric='service-rate', bf=m_model,\n",
    "            job_size_distribution='zipf', mean_job_size=3.584282)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two servers (the N model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_model(rho, i):\n",
    "    return .5 / (1 - rho) + (i == 1) * (.5 + .5 / (1. - rho)) / (2. - 2. * rho + rho * rho / 2.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bimodal number of exponentially-distributed phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='n', metric='delay', bf=n_model,\n",
    "            job_size_distribution='bimodal', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='n', metric='service-rate', bf=n_model,\n",
    "            job_size_distribution='bimodal', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperexponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='n', metric='delay', bf=n_model,\n",
    "            job_size_distribution='hyperexp', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='n', metric='service-rate', bf=n_model,\n",
    "            job_size_distribution='hyperexp', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zipf number of exponentially-distributed phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='n', metric='delay', bf=n_model,\n",
    "            job_size_distribution='zipf', mean_job_size=3.584282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_example(scenario='n', metric='service-rate', bf=n_model,\n",
    "            job_size_distribution='zipf', mean_job_size=3.584282)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large system with a random job assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def random(degree, metric, job_size_distribution, mean_job_size):\n",
    "    figure()\n",
    "    maximum = 0.\n",
    "    \n",
    "    # theoretical results\n",
    "    #binom = ones(100 - degree + 1)\n",
    "    #binom[1:] = cumprod(1. + (degree - 1.) / arange(1, 100 - degree + 1))\n",
    "    #bf = sum(1. / (1. - outer(rho, binom / binom[-1])) - 1., axis=1) / (100 * rho)\n",
    "    binom = ones(100 - degree + 1)\n",
    "    binom[1:] = cumprod(1. + (degree - 1.) / arange(1, 100 - degree + 1))\n",
    "    bf = sum(1. / ( binom[-1] / binom.reshape((1, 100-degree+1))\n",
    "                   - rho.reshape((len(rho),1)) ), axis=1) / 100\n",
    "    if metric == 'service-rate':\n",
    "        plot(rho, 1. / bf, label='Balanced fairness', color='C0')\n",
    "    elif metric == 'delay':\n",
    "        plot(rho, mean_job_size * bf, label='Balanced fairness', color='C0')\n",
    "\n",
    "    for j, timer in enumerate([5, 1, 0]):\n",
    "        # read the simulation results\n",
    "        result = pd.read_csv('%srandom-%d-%s-%d-%s.csv'\n",
    "                             % (folder, degree, job_size_distribution, timer, metric))\n",
    "\n",
    "        # plot the simulation results\n",
    "        plot(result['rho'], result['performance'],\n",
    "             label='m = %d' % timer, marker=markers[j], color='C%d' % (j+1), linestyle='None')\n",
    "        fill_between(result['rho'],\n",
    "                     (result['performance'] - result['interval']),\n",
    "                     (result['performance'] + result['interval']),\n",
    "                     color='C%d' % (j+1), alpha=.3)\n",
    "            \n",
    "        # remember the maximum ordinate\n",
    "        maximum = max(maximum, np.max(result['performance'] + result['interval']))\n",
    "\n",
    "    title('Average over all pools (regular-%d - %s - %s)' % (degree, job_size_distribution, metric))\n",
    "    xlim(0, 1); ylim(0, maximum)\n",
    "    legend(loc='best')\n",
    "    show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree two"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Bimodal number of exponentially-distributed phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random(degree=2, metric='delay', job_size_distribution='bimodal', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random(degree=2, metric='service-rate', job_size_distribution='bimodal', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Hyperexponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random(degree=2, metric='delay', job_size_distribution='hyperexp', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random(degree=2, metric='service-rate', job_size_distribution='hyperexp', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### Zipf number of exponentially-distributed phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random(degree=2, metric='delay', job_size_distribution='zipf', mean_job_size=3.584282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "random(degree=2, metric='service-rate', job_size_distribution='zipf', mean_job_size=3.584282)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Degree three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bimodal number of exponentially-distributed phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random(degree=3, metric='delay', job_size_distribution='bimodal', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random(degree=3, metric='service-rate', job_size_distribution='bimodal', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperexponential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random(degree=3, metric='delay', job_size_distribution='hyperexp', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random(degree=3, metric='service-rate', job_size_distribution='hyperexp', mean_job_size=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Zipf number of exponentially-distributed phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random(degree=3, metric='delay', job_size_distribution='zipf', mean_job_size=3.584282)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random(degree=3, metric='service-rate', job_size_distribution='zipf', mean_job_size=3.584282)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
